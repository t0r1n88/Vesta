{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ddccf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.\tНужно чтобы программа обновляла данные в столбцах которые есть в первой таблице при совпадении идентификатора.\n",
    "2.\tДобавляла данные в соответствующие столбцы если такого идентификатора нет в первой таблице\n",
    "Скорее всего нужно создавать дополнительный лист в главном файле и сохранять его отдельно, так будет проще\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl.styles import Alignment\n",
    "from openpyxl import load_workbook\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from tkinter import ttk\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "from dateutil.parser import ParserError\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')\n",
    "pd.options.mode.chained_assignment = None\n",
    "import sys\n",
    "import locale\n",
    "import logging\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1949d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_params_columns_to_int(lst):\n",
    "    \"\"\"\n",
    "    Функция для конвератации значений колонок которые нужно обработать.\n",
    "    Очищает от пустых строк, чтобы в итоге остался список из чисел в формате int\n",
    "    \"\"\"\n",
    "    out_lst = [] # Создаем список в который будем добавлять только числа\n",
    "    for value in lst: # Перебираем список\n",
    "        try:\n",
    "            # Обрабатываем случай с нулем, для того чтобы после приведения к питоновскому отсчету от нуля не получилась колонка с номером -1\n",
    "            number = int(value)\n",
    "            if number != 0:\n",
    "                out_lst.append(value) # Если конвертирования прошло без ошибок то добавляем\n",
    "            else:\n",
    "                continue\n",
    "        except: # Иначе пропускаем\n",
    "            continue\n",
    "    return out_lst\n",
    "\n",
    "\n",
    "def convert_columns_to_str(df, number_columns):\n",
    "    \"\"\"\n",
    "    Функция для конвертации указанных столбцов в строковый тип и очистки от пробельных символов в начале и конце\n",
    "    \"\"\"\n",
    "\n",
    "    for column in number_columns:  # Перебираем список нужных колонок\n",
    "        try:\n",
    "            df.iloc[:, column] = df.iloc[:, column].astype(str)\n",
    "            # Очищаем колонку от пробельных символов с начала и конца\n",
    "            df.iloc[:, column] = df.iloc[:, column].apply(lambda x: x.strip())\n",
    "        except IndexError:\n",
    "            messagebox.showerror('Веста Обработка таблиц и создание документов ver 1.21',\n",
    "                                 'Проверьте порядковые номера колонок которые вы хотите обработать.')\n",
    "            \n",
    "def processing_date_column(df, lst_columns):\n",
    "    \"\"\"\n",
    "    Функция для обработки столбцов с датами. конвертация в строку формата ДД.ММ.ГГГГ\n",
    "    \"\"\"\n",
    "    # получаем первую строку\n",
    "    first_row = df.iloc[0, lst_columns]\n",
    "\n",
    "    lst_first_row = list(first_row)  # Превращаем строку в список\n",
    "    lst_date_columns = []  # Создаем список куда будем сохранять колонки в которых находятся даты\n",
    "    tupl_row = list(zip(lst_columns,\n",
    "                        lst_first_row))  # Создаем список кортежей формата (номер колонки,значение строки в этой колонке)\n",
    "\n",
    "    for idx, value in tupl_row:  # Перебираем кортеж\n",
    "        result = check_date_columns(idx, value)  # проверяем является ли значение датой\n",
    "        if result:  # если да то добавляем список порядковый номер колонки\n",
    "            lst_date_columns.append(result)\n",
    "        else:  # иначе проверяем следующее значение\n",
    "            continue\n",
    "    for i in lst_date_columns:  # Перебираем список с колонками дат, превращаем их в даты и конвертируем в нужный строковый формат\n",
    "        df.iloc[:, i] = pd.to_datetime(df.iloc[:, i], errors='coerce', dayfirst=True)\n",
    "        df.iloc[:, i] = df.iloc[:, i].apply(create_doc_convert_date)\n",
    "\n",
    "def check_date_columns(i, value):\n",
    "    \"\"\"\n",
    "    Функция для проверки типа колонки. Необходимо найти колонки с датой\n",
    "    :param i:\n",
    "    :param value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        itog = pd.to_datetime(str(value), infer_datetime_format=True)\n",
    "\n",
    "    except ParserError:\n",
    "        pass\n",
    "    except ValueError:\n",
    "        pass\n",
    "    except TypeError:\n",
    "        pass\n",
    "    else:\n",
    "        return i\n",
    "\n",
    "def create_doc_convert_date(cell):\n",
    "    \"\"\"\n",
    "    Функция для конвертации даты при создании документов\n",
    "    :param cell:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        string_date = datetime.datetime.strftime(cell, '%d.%m.%Y')\n",
    "        return string_date\n",
    "    except ValueError:\n",
    "        return 'Не удалось конвертировать дату.Проверьте значение ячейки!!!'\n",
    "    except TypeError:\n",
    "        return 'Не удалось конвертировать дату.Проверьте значение ячейки!!!'    \n",
    "    \n",
    "def clean_ending_columns(lst_columns:list,name_first_df,name_second_df):\n",
    "    \"\"\"\n",
    "    Функция для очистки колонок таблицы с совпадающими данными от окончаний _x _y\n",
    "\n",
    "    :param lst_columns:\n",
    "    :param time_generate\n",
    "    :param name_first_df\n",
    "    :param name_second_df\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    out_columns = [] # список для очищенных названий\n",
    "    for name_column in lst_columns:\n",
    "        if '_x' in name_column:\n",
    "            # если они есть то проводим очистку и добавление времени\n",
    "            cut_name_column = name_column[:-2] # обрезаем\n",
    "            temp_name = f'{cut_name_column}_{name_first_df}' # соединяем\n",
    "            out_columns.append(temp_name) # добавляем\n",
    "        elif '_y' in name_column:\n",
    "            cut_name_column = name_column[:-2]  # обрезаем\n",
    "            temp_name = f'{cut_name_column}_{name_second_df}'  # соединяем\n",
    "            out_columns.append(temp_name)  # добавляем\n",
    "        else:\n",
    "            out_columns.append(name_column)\n",
    "    return out_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380fb6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0339c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем значения текстовых полей\n",
    "# first_sheet_name = str(entry_first_sheet_name.get())\n",
    "# second_sheet_name = str(entry_second_sheet_name.get())\n",
    "\n",
    "# # загружаем файлы\n",
    "# first_df = pd.read_excel(name_first_file_comparison, sheet_name=first_sheet_name, dtype=str,\n",
    "#                          keep_default_na=False)\n",
    "# # получаем имя файла\n",
    "# name_first_df = name_first_file_comparison.split('/')[-1]\n",
    "# name_first_df = name_first_df.split('.xlsx')[0]\n",
    "\n",
    "# second_df = pd.read_excel(name_second_file_comparison, sheet_name=second_sheet_name, dtype=str,\n",
    "#                           keep_default_na=False)\n",
    "# # получаем имя файла\n",
    "# name_second_df = name_second_file_comparison.split('/')[-1]\n",
    "# name_second_df = name_second_df.split('.xlsx')[0]\n",
    "\n",
    "# params = pd.read_excel(file_params, header=None, keep_default_na=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5adab280",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sheet_name = 'Sheet1'\n",
    "second_sheet_name = 'Лист1'\n",
    "# first_sheet_name = 'Sheet1'\n",
    "# second_sheet_name = 'Sheet1'\n",
    "name_first_file_comparison = 'data/1000 без персональных данных.xlsx'\n",
    "name_second_file_comparison = 'data/Список в табличном виде № 336 “Об утверждении перечней профессий и специальностей среднего профессионального образования от  17 мая 2022 г..xlsx'\n",
    "\n",
    "# name_first_file_comparison = 'data/Таблица с обновленными данными и колонками от 13_46_50.xlsx'\n",
    "# name_second_file_comparison = 'data/Социалка 2.xlsx'\n",
    "\n",
    "file_params = 'data/параметры слияния для укрупненных групп.xlsx'\n",
    "path_to_end_folder_comparison = 'data'\n",
    "\n",
    "first_df = pd.read_excel(name_first_file_comparison, sheet_name=first_sheet_name, dtype=str,\n",
    "                         keep_default_na=False)\n",
    "# получаем имя файла\n",
    "name_first_df = name_first_file_comparison.split('/')[-1]\n",
    "name_first_df = name_first_df.split('.xlsx')[0]\n",
    "\n",
    "second_df = pd.read_excel(name_second_file_comparison, sheet_name=second_sheet_name, dtype=str,\n",
    "                          keep_default_na=False)\n",
    "# получаем имя файла\n",
    "name_second_df = name_second_file_comparison.split('/')[-1]\n",
    "name_second_df = name_second_df.split('.xlsx')[0]\n",
    "\n",
    "params = pd.read_excel(file_params, header=None, keep_default_na=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "296c1f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Группа</th>\n",
       "      <th>ФИО</th>\n",
       "      <th>Дата рождения</th>\n",
       "      <th>Пол</th>\n",
       "      <th>Состояние</th>\n",
       "      <th>Доп статус</th>\n",
       "      <th>Средний балл</th>\n",
       "      <th>Код профессии специальности</th>\n",
       "      <th>Професиия_Специальность</th>\n",
       "      <th>Курс</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ДА-989</td>\n",
       "      <td>Алехин Данила Прокопьевич</td>\n",
       "      <td>14.04.1973</td>\n",
       "      <td>М</td>\n",
       "      <td>Обучается</td>\n",
       "      <td>Нет статуса</td>\n",
       "      <td>3</td>\n",
       "      <td>24.01.01</td>\n",
       "      <td>Слесарь-сборщик авиационной техники</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ДА-989</td>\n",
       "      <td>Эсаулова Валерия Прокловна</td>\n",
       "      <td>20.08.1976</td>\n",
       "      <td>Ж</td>\n",
       "      <td>Обучается</td>\n",
       "      <td>Нет статуса</td>\n",
       "      <td>4.4</td>\n",
       "      <td>24.01.01</td>\n",
       "      <td>Слесарь-сборщик авиационной техники</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ДА-989</td>\n",
       "      <td>Панин Гавриил Власович</td>\n",
       "      <td>25.10.1990</td>\n",
       "      <td>М</td>\n",
       "      <td>Служба в РА</td>\n",
       "      <td>Нет статуса</td>\n",
       "      <td>3.52</td>\n",
       "      <td>24.01.01</td>\n",
       "      <td>Слесарь-сборщик авиационной техники</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ДА-989</td>\n",
       "      <td>Грибанов Константин Степанович</td>\n",
       "      <td>06.09.1989</td>\n",
       "      <td>М</td>\n",
       "      <td>Обучается</td>\n",
       "      <td>Нет статуса</td>\n",
       "      <td>3.22</td>\n",
       "      <td>24.01.01</td>\n",
       "      <td>Слесарь-сборщик авиационной техники</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ДА-989</td>\n",
       "      <td>Мандрыко Трофим Леонидович</td>\n",
       "      <td>12.01.1965</td>\n",
       "      <td>М</td>\n",
       "      <td>Обучается</td>\n",
       "      <td>Нет статуса</td>\n",
       "      <td>3.37</td>\n",
       "      <td>24.01.01</td>\n",
       "      <td>Слесарь-сборщик авиационной техники</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Группа                             ФИО Дата рождения Пол    Состояние  \\\n",
       "0  ДА-989       Алехин Данила Прокопьевич    14.04.1973   М    Обучается   \n",
       "1  ДА-989      Эсаулова Валерия Прокловна    20.08.1976   Ж    Обучается   \n",
       "2  ДА-989          Панин Гавриил Власович    25.10.1990   М  Служба в РА   \n",
       "3  ДА-989  Грибанов Константин Степанович    06.09.1989   М    Обучается   \n",
       "4  ДА-989      Мандрыко Трофим Леонидович    12.01.1965   М    Обучается   \n",
       "\n",
       "    Доп статус Средний балл Код профессии специальности  \\\n",
       "0  Нет статуса            3                    24.01.01   \n",
       "1  Нет статуса          4.4                    24.01.01   \n",
       "2  Нет статуса         3.52                    24.01.01   \n",
       "3  Нет статуса         3.22                    24.01.01   \n",
       "4  Нет статуса         3.37                    24.01.01   \n",
       "\n",
       "               Професиия_Специальность Курс  \n",
       "0  Слесарь-сборщик авиационной техники    1  \n",
       "1  Слесарь-сборщик авиационной техники    1  \n",
       "2  Слесарь-сборщик авиационной техники    1  \n",
       "3  Слесарь-сборщик авиационной техники    1  \n",
       "4  Слесарь-сборщик авиационной техники    1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86668ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Преврашаем каждую колонку в список\n",
    "params_first_columns = params[0].tolist()\n",
    "params_second_columns = params[1].tolist()\n",
    "\n",
    "# Конвертируем в инт заодно проверяя корректность введенных данных\n",
    "int_params_first_columns = convert_params_columns_to_int(params_first_columns)\n",
    "int_params_second_columns = convert_params_columns_to_int(params_second_columns)\n",
    "\n",
    "# Отнимаем 1 от каждого значения чтобы привести к питоновским индексам\n",
    "int_params_first_columns = list(map(lambda x: x - 1, int_params_first_columns))\n",
    "int_params_second_columns = list(map(lambda x: x - 1, int_params_second_columns))\n",
    "\n",
    "# Конвертируем нужные нам колонки в str\n",
    "convert_columns_to_str(first_df, int_params_first_columns)\n",
    "convert_columns_to_str(second_df, int_params_second_columns)\n",
    "\n",
    "# в этом месте конвертируем даты в формат ДД.ММ.ГГГГ\n",
    "processing_date_column(first_df, int_params_first_columns)\n",
    "processing_date_column(second_df, int_params_second_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "179369f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем наличие колонки _merge\n",
    "if '_merge' in first_df.columns:\n",
    "    first_df.drop(columns=['_merge'], inplace=True)\n",
    "if '_merge' in second_df.columns:\n",
    "    second_df.drop(columns=['_merge'], inplace=True)\n",
    "# Проверяем наличие колонки ID\n",
    "if 'ID_объединения' in first_df.columns:\n",
    "    first_df.drop(columns=['ID_объединения'], inplace=True)\n",
    "if 'ID_объединения' in second_df.columns:\n",
    "    second_df.drop(columns=['ID_объединения'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0fffd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Создаем в каждом датафрейме колонку с айди путем склеивания всех нужных колонок в одну строку\n",
    "first_df['ID_объединения'] = first_df.iloc[:, int_params_first_columns].sum(axis=1)\n",
    "second_df['ID_объединения'] = second_df.iloc[:, int_params_second_columns].sum(axis=1)\n",
    "# Удаляем все пробелы чтобы они не повлияли на слияние\n",
    "first_df['ID_объединения'] = first_df['ID_объединения'].apply(lambda x: x.replace(' ', ''))\n",
    "second_df['ID_объединения'] = second_df['ID_объединения'].apply(lambda x: x.replace(' ', ''))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d4aa9728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Группа                         object\n",
       "ФИО                            object\n",
       "Дата рождения                  object\n",
       "Пол                            object\n",
       "Состояние                      object\n",
       "Доп статус                     object\n",
       "Средний балл                   object\n",
       "Код профессии специальности    object\n",
       "Професиия_Специальность        object\n",
       "Курс                           object\n",
       "ID_объединения                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85e88f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Группа</th>\n",
       "      <th>ФИО</th>\n",
       "      <th>Дата рождения</th>\n",
       "      <th>Пол</th>\n",
       "      <th>Состояние</th>\n",
       "      <th>Доп статус</th>\n",
       "      <th>Средний балл</th>\n",
       "      <th>Код профессии специальности</th>\n",
       "      <th>Професиия_Специальность</th>\n",
       "      <th>Курс</th>\n",
       "      <th>ID_объединения</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ДА-989</td>\n",
       "      <td>Алехин Данила Прокопьевич</td>\n",
       "      <td>14.04.1973</td>\n",
       "      <td>М</td>\n",
       "      <td>Обучается</td>\n",
       "      <td>Нет статуса</td>\n",
       "      <td>3</td>\n",
       "      <td>24.01.2001</td>\n",
       "      <td>Слесарь-сборщик авиационной техники</td>\n",
       "      <td>1</td>\n",
       "      <td>24.01.2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ДА-989</td>\n",
       "      <td>Эсаулова Валерия Прокловна</td>\n",
       "      <td>20.08.1976</td>\n",
       "      <td>Ж</td>\n",
       "      <td>Обучается</td>\n",
       "      <td>Нет статуса</td>\n",
       "      <td>4.4</td>\n",
       "      <td>24.01.2001</td>\n",
       "      <td>Слесарь-сборщик авиационной техники</td>\n",
       "      <td>1</td>\n",
       "      <td>24.01.2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Группа                         ФИО Дата рождения Пол  Состояние  \\\n",
       "0  ДА-989   Алехин Данила Прокопьевич    14.04.1973   М  Обучается   \n",
       "1  ДА-989  Эсаулова Валерия Прокловна    20.08.1976   Ж  Обучается   \n",
       "\n",
       "    Доп статус Средний балл Код профессии специальности  \\\n",
       "0  Нет статуса            3                  24.01.2001   \n",
       "1  Нет статуса          4.4                  24.01.2001   \n",
       "\n",
       "               Професиия_Специальность Курс ID_объединения  \n",
       "0  Слесарь-сборщик авиационной техники    1     24.01.2001  \n",
       "1  Слесарь-сборщик авиационной техники    1     24.01.2001  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f792e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3.00\n",
       "1      4.40\n",
       "2      3.52\n",
       "3      3.22\n",
       "4      3.37\n",
       "       ... \n",
       "995    3.09\n",
       "996    3.21\n",
       "997    3.86\n",
       "998    4.07\n",
       "999    3.64\n",
       "Name: Средний балл, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_df['Средний балл'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58ec2a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Worksheet \"Объединённая таблица\">"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В результат объединения попадают совпадающие по ключу записи обеих таблиц и все строки из этих двух таблиц, для которых пар не нашлось. Порядок таблиц в запросе не\n",
    "\n",
    "# Создаем документ\n",
    "wb = openpyxl.Workbook()\n",
    "# создаем листы\n",
    "ren_sheet = wb['Sheet']\n",
    "ren_sheet.title = 'Таблица 1'\n",
    "wb.create_sheet(title='Таблица 2', index=1)\n",
    "wb.create_sheet(title='Совпадающие данные', index=2)\n",
    "wb.create_sheet(title='Обновленная таблица', index=3)\n",
    "wb.create_sheet(title='Объединённая таблица', index=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95d5e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем переменные содержащие в себе количество колонок в базовых датареймах\n",
    "first_df_quantity_cols = len(first_df.columns)  # не забываем что там добавилась колонка ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0fd27d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Проводим слияние\n",
    "itog_df = pd.merge(first_df, second_df, how='outer', left_on=['ID_объединения'], right_on=['ID_объединения'],\n",
    "                   indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2af14507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# копируем в отдельный датафрейм для создания таблицы с обновлениями\n",
    "update_df = itog_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2433c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Записываем каждый датафрейм в соответсвующий лист\n",
    "# Левая таблица\n",
    "left_df = itog_df[itog_df['_merge'] == 'left_only']\n",
    "left_df.drop(['_merge'], axis=1, inplace=True)\n",
    "\n",
    "# Удаляем колонки второй таблицы чтобы не мешались\n",
    "left_df.drop(left_df.iloc[:, first_df_quantity_cols:], axis=1, inplace=True)\n",
    "\n",
    "# Переименовываем колонки у которых были совпадение во второй таблице, в таких колонках есть добавление _x\n",
    "clean_left_columns = list(map(lambda x: x[:-2] if '_x' in x else x, list(left_df.columns)))\n",
    "left_df.columns = clean_left_columns\n",
    "for r in dataframe_to_rows(left_df, index=False, header=True):\n",
    "    wb['Таблица 1'].append(r)\n",
    "\n",
    "right_df = itog_df[itog_df['_merge'] == 'right_only']\n",
    "right_df.drop(['_merge'], axis=1, inplace=True)\n",
    "\n",
    "# Удаляем колонки первой таблицы таблицы чтобы не мешались\n",
    "right_df.drop(right_df.iloc[:, :first_df_quantity_cols - 1], axis=1, inplace=True)\n",
    "\n",
    "# Переименовываем колонки у которых были совпадение во второй таблице, в таких колонках есть добавление _x\n",
    "clean_right_columns = list(map(lambda x: x[:-2] if '_y' in x else x, list(right_df.columns)))\n",
    "right_df.columns = clean_right_columns\n",
    "\n",
    "for r in dataframe_to_rows(right_df, index=False, header=True):\n",
    "    wb['Таблица 2'].append(r)\n",
    "\n",
    "both_df = itog_df[itog_df['_merge'] == 'both']\n",
    "both_df.drop(['_merge'], axis=1, inplace=True)\n",
    "# Очищаем от _x  и _y\n",
    "clean_both_columns = clean_ending_columns(list(both_df.columns), name_first_df, name_second_df)\n",
    "both_df.columns = clean_both_columns\n",
    "\n",
    "for r in dataframe_to_rows(both_df, index=False, header=True):\n",
    "    wb['Совпадающие данные'].append(r)\n",
    "\n",
    "# Сохраняем общую таблицу\n",
    "# Заменяем названия индикаторов на более понятные\n",
    "itog_df['_merge'] = itog_df['_merge'].apply(lambda x: 'Данные из первой таблицы' if x == 'left_only' else\n",
    "('Данные из второй таблицы' if x == 'right_only' else 'Совпадающие данные'))\n",
    "itog_df['_merge'] = itog_df['_merge'].astype(str)\n",
    "\n",
    "clean_itog_df = clean_ending_columns(list(itog_df.columns), name_first_df, name_second_df)\n",
    "itog_df.columns = clean_itog_df\n",
    "for r in dataframe_to_rows(itog_df, index=False, header=True):\n",
    "    wb['Объединённая таблица'].append(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "963bf52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# получаем список с совпадающими колонками первой таблицы\n",
    "first_df_columns = [column for column in list(update_df.columns) if str(column).endswith('_x')]\n",
    "# получаем список с совпадающими колонками второй таблицы\n",
    "second_df_columns = [column for column in list(update_df.columns) if str(column).endswith('_y')]\n",
    "# Создаем из списка совпадающих колонок второй таблицы словарь, чтобы было легче обрабатывать\n",
    "# да конечно можно было сделать в одном выражении но как я буду читать это через 2 недели?\n",
    "dct_second_columns = {column.split('_y')[0]:column for column in second_df_columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50e20607",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in first_df_columns:\n",
    "    # очищаем от _x\n",
    "    name_column = column.split('_x')[0]\n",
    "    # Обновляем значение в случае если в колонке _merge стоит both, иначе оставляем старое значение,\n",
    "    # Чтобы обновить значение в ячейке, во второй таблице не должно быть пустого значения или пробела в аналогичной колонке\n",
    "    \n",
    "    update_df[column] = np.where((update_df['_merge']=='both') & (update_df[dct_second_columns[name_column]]) & (update_df[dct_second_columns[name_column]] != ' '),update_df[dct_second_columns[name_column]],update_df[column]) \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d9e98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b110c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "050e8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем колонки с _y\n",
    "update_df.drop(columns=[column for column in update_df.columns if column.endswith('_y')],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "49b1926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переименовываем колонки с _x\n",
    "update_df.columns = list(map(lambda x:x[:-2] if x.endswith('_x') else x,update_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ba71c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем строки с _merge == right_only\n",
    "update_df = update_df[update_df['_merge'] != 'right_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03aab2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем служебные колонки\n",
    "update_df.drop(columns=['ID_объединения','_merge'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10c7daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем лишнюю колонку в right_df\n",
    "right_df.drop(columns=['ID_объединения'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "25e1b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем нехватающие колонки\n",
    "new_right_df = right_df.reindex(columns=update_df.columns,fill_value=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "594d2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_df = pd.concat([update_df,new_right_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e0bc285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in dataframe_to_rows(update_df, index=False, header=True):\n",
    "    wb['Обновленная таблица'].append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59addba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480e468f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bb06312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем текущее время\n",
    "t = time.localtime()\n",
    "current_time = time.strftime('%H_%M_%S', t)\n",
    "# Сохраняем итоговый файл\n",
    "wb.save(f'{path_to_end_folder_comparison}/Результат слияния 2 таблиц от {current_time}.xlsx')\n",
    "# Сохраняем отдельно обновленную таблицу\n",
    "update_df.to_excel(f'{path_to_end_folder_comparison}/Таблица с обновленными данными и колонками от {current_time}.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8b8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d250a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197564ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2972d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40210f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5067cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340af2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba1865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeccb615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac6f712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae02624d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d2792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d35ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57f3b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4acdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b583ec85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65c90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cac6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fdb008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
