{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ed877c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.\tНужно чтобы программа обновляла данные в столбцах которые есть в первой таблице при совпадении идентификатора.\n",
    "2.\tДобавляла данные в соответствующие столбцы если такого идентификатора нет в первой таблице\n",
    "Скорее всего нужно создавать дополнительный лист в главном файле и сохранять его отдельно, так будет проще\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl.styles import Alignment\n",
    "from openpyxl import load_workbook\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from tkinter import ttk\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "from dateutil.parser import ParserError\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')\n",
    "pd.options.mode.chained_assignment = None\n",
    "import sys\n",
    "import locale\n",
    "import logging\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1bd2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_params_columns_to_int(lst):\n",
    "    \"\"\"\n",
    "    Функция для конвератации значений колонок которые нужно обработать.\n",
    "    Очищает от пустых строк, чтобы в итоге остался список из чисел в формате int\n",
    "    \"\"\"\n",
    "    out_lst = [] # Создаем список в который будем добавлять только числа\n",
    "    for value in lst: # Перебираем список\n",
    "        try:\n",
    "            # Обрабатываем случай с нулем, для того чтобы после приведения к питоновскому отсчету от нуля не получилась колонка с номером -1\n",
    "            number = int(value)\n",
    "            if number != 0:\n",
    "                out_lst.append(value) # Если конвертирования прошло без ошибок то добавляем\n",
    "            else:\n",
    "                continue\n",
    "        except: # Иначе пропускаем\n",
    "            continue\n",
    "    return out_lst\n",
    "\n",
    "\n",
    "def convert_columns_to_str(df, number_columns):\n",
    "    \"\"\"\n",
    "    Функция для конвертации указанных столбцов в строковый тип и очистки от пробельных символов в начале и конце\n",
    "    \"\"\"\n",
    "\n",
    "    for column in number_columns:  # Перебираем список нужных колонок\n",
    "        try:\n",
    "            df.iloc[:, column] = df.iloc[:, column].astype(str)\n",
    "            # Очищаем колонку от пробельных символов с начала и конца\n",
    "            df.iloc[:, column] = df.iloc[:, column].apply(lambda x: x.strip())\n",
    "        except IndexError:\n",
    "            messagebox.showerror('Веста Обработка таблиц и создание документов ver 1.21',\n",
    "                                 'Проверьте порядковые номера колонок которые вы хотите обработать.')\n",
    "            \n",
    "def processing_date_column(df, lst_columns):\n",
    "    \"\"\"\n",
    "    Функция для обработки столбцов с датами. конвертация в строку формата ДД.ММ.ГГГГ\n",
    "    \"\"\"\n",
    "    # получаем первую строку\n",
    "    first_row = df.iloc[0, lst_columns]\n",
    "\n",
    "    lst_first_row = list(first_row)  # Превращаем строку в список\n",
    "    lst_date_columns = []  # Создаем список куда будем сохранять колонки в которых находятся даты\n",
    "    tupl_row = list(zip(lst_columns,\n",
    "                        lst_first_row))  # Создаем список кортежей формата (номер колонки,значение строки в этой колонке)\n",
    "\n",
    "    for idx, value in tupl_row:  # Перебираем кортеж\n",
    "        result = check_date_columns(idx, value)  # проверяем является ли значение датой\n",
    "        if result:  # если да то добавляем список порядковый номер колонки\n",
    "            lst_date_columns.append(result)\n",
    "        else:  # иначе проверяем следующее значение\n",
    "            continue\n",
    "    for i in lst_date_columns:  # Перебираем список с колонками дат, превращаем их в даты и конвертируем в нужный строковый формат\n",
    "        df.iloc[:, i] = pd.to_datetime(df.iloc[:, i], errors='coerce', dayfirst=True)\n",
    "        df.iloc[:, i] = df.iloc[:, i].apply(create_doc_convert_date)\n",
    "\n",
    "def check_date_columns(i, value):\n",
    "    \"\"\"\n",
    "    Функция для проверки типа колонки. Необходимо найти колонки с датой\n",
    "    :param i:\n",
    "    :param value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        itog = pd.to_datetime(str(value), infer_datetime_format=True)\n",
    "\n",
    "    except ParserError:\n",
    "        pass\n",
    "    except ValueError:\n",
    "        pass\n",
    "    except TypeError:\n",
    "        pass\n",
    "    else:\n",
    "        return i\n",
    "\n",
    "def create_doc_convert_date(cell):\n",
    "    \"\"\"\n",
    "    Функция для конвертации даты при создании документов\n",
    "    :param cell:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        string_date = datetime.datetime.strftime(cell, '%d.%m.%Y')\n",
    "        return string_date\n",
    "    except ValueError:\n",
    "        return 'Не удалось конвертировать дату.Проверьте значение ячейки!!!'\n",
    "    except TypeError:\n",
    "        return 'Не удалось конвертировать дату.Проверьте значение ячейки!!!'    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f66a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_value(orig_value,new_value,value_filter):\n",
    "    \"\"\"\n",
    "    Функция обновляет данные в колонке зависимости от значения в колонке фильтре   \n",
    "    \"\"\"\n",
    "    if value_filter == 'both':\n",
    "        return new_value\n",
    "    else:\n",
    "        return orig_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28bffab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfac732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем значения текстовых полей\n",
    "# first_sheet_name = str(entry_first_sheet_name.get())\n",
    "# second_sheet_name = str(entry_second_sheet_name.get())\n",
    "\n",
    "# # загружаем файлы\n",
    "# first_df = pd.read_excel(name_first_file_comparison, sheet_name=first_sheet_name, dtype=str,\n",
    "#                          keep_default_na=False)\n",
    "# # получаем имя файла\n",
    "# name_first_df = name_first_file_comparison.split('/')[-1]\n",
    "# name_first_df = name_first_df.split('.xlsx')[0]\n",
    "\n",
    "# second_df = pd.read_excel(name_second_file_comparison, sheet_name=second_sheet_name, dtype=str,\n",
    "#                           keep_default_na=False)\n",
    "# # получаем имя файла\n",
    "# name_second_df = name_second_file_comparison.split('/')[-1]\n",
    "# name_second_df = name_second_df.split('.xlsx')[0]\n",
    "\n",
    "# params = pd.read_excel(file_params, header=None, keep_default_na=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34603398",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sheet_name = 'Worksheet'\n",
    "second_sheet_name = 'Лист1'\n",
    "name_first_file_comparison = 'data/Основная таблица.xlsx'\n",
    "name_second_file_comparison = 'data/Социалка.xlsx'\n",
    "file_params = 'data/Параметры слияния.xlsx'\n",
    "\n",
    "first_df = pd.read_excel(name_first_file_comparison, sheet_name=first_sheet_name, dtype=str,\n",
    "                         keep_default_na=False)\n",
    "# получаем имя файла\n",
    "name_first_df = name_first_file_comparison.split('/')[-1]\n",
    "name_first_df = name_first_df.split('.xlsx')[0]\n",
    "\n",
    "second_df = pd.read_excel(name_second_file_comparison, sheet_name=second_sheet_name, dtype=str,\n",
    "                          keep_default_na=False)\n",
    "# получаем имя файла\n",
    "name_second_df = name_second_file_comparison.split('/')[-1]\n",
    "name_second_df = name_second_df.split('.xlsx')[0]\n",
    "\n",
    "params = pd.read_excel(file_params, header=None, keep_default_na=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6618182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Преврашаем каждую колонку в список\n",
    "params_first_columns = params[0].tolist()\n",
    "params_second_columns = params[1].tolist()\n",
    "\n",
    "# Конвертируем в инт заодно проверяя корректность введенных данных\n",
    "int_params_first_columns = convert_params_columns_to_int(params_first_columns)\n",
    "int_params_second_columns = convert_params_columns_to_int(params_second_columns)\n",
    "\n",
    "# Отнимаем 1 от каждого значения чтобы привести к питоновским индексам\n",
    "int_params_first_columns = list(map(lambda x: x - 1, int_params_first_columns))\n",
    "int_params_second_columns = list(map(lambda x: x - 1, int_params_second_columns))\n",
    "\n",
    "# Конвертируем нужные нам колонки в str\n",
    "convert_columns_to_str(first_df, int_params_first_columns)\n",
    "convert_columns_to_str(second_df, int_params_second_columns)\n",
    "\n",
    "# в этом месте конвертируем даты в формат ДД.ММ.ГГГГ\n",
    "processing_date_column(first_df, int_params_first_columns)\n",
    "processing_date_column(second_df, int_params_second_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ca9878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем наличие колонки _merge\n",
    "if '_merge' in first_df.columns:\n",
    "    first_df.drop(columns=['_merge'], inplace=True)\n",
    "if '_merge' in second_df.columns:\n",
    "    second_df.drop(columns=['_merge'], inplace=True)\n",
    "# Проверяем наличие колонки ID\n",
    "if 'ID_объединения' in first_df.columns:\n",
    "    first_df.drop(columns=['ID_объединения'], inplace=True)\n",
    "if 'ID_объединения' in second_df.columns:\n",
    "    second_df.drop(columns=['ID_объединения'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da75d340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Фамилия</th>\n",
       "      <th>Имя</th>\n",
       "      <th>Отчество</th>\n",
       "      <th>ФИО</th>\n",
       "      <th>Дата рождения</th>\n",
       "      <th>Номер телефона</th>\n",
       "      <th>Электронная почта</th>\n",
       "      <th>Адрес прописки</th>\n",
       "      <th>Фактический адрес</th>\n",
       "      <th>Серия и номер паспорта</th>\n",
       "      <th>Серия паспорта</th>\n",
       "      <th>Номер паспорта</th>\n",
       "      <th>Код подразделения</th>\n",
       "      <th>Кем выдан</th>\n",
       "      <th>Дата выдачи паспорта</th>\n",
       "      <th>ИНН ФЗ/ИП</th>\n",
       "      <th>СНИЛС</th>\n",
       "      <th>ОМС</th>\n",
       "      <th>Направление</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Алехин</td>\n",
       "      <td>Данила</td>\n",
       "      <td>Прокопьевич</td>\n",
       "      <td>Алехин Данила Прокопьевич</td>\n",
       "      <td>14.04.1973</td>\n",
       "      <td>+7 (951) 885-25-41</td>\n",
       "      <td>danila79@hotmail.com</td>\n",
       "      <td>Россия, г. Иркутск, Кирова ул., д. 1 кв.212</td>\n",
       "      <td>Россия, г. Екатеринбург, Кирова ул., д. 1 кв.107</td>\n",
       "      <td>4844 295530</td>\n",
       "      <td>4844</td>\n",
       "      <td>295530</td>\n",
       "      <td>330-554</td>\n",
       "      <td>ОУФМС России по г. Екатеринбург</td>\n",
       "      <td>08.08.2020</td>\n",
       "      <td>158493217864</td>\n",
       "      <td>707-920-812 02</td>\n",
       "      <td>5950614844448865</td>\n",
       "      <td>02.03.03 Математическое обеспечение и админист...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Фамилия     Имя     Отчество                        ФИО Дата рождения  \\\n",
       "0  Алехин  Данила  Прокопьевич  Алехин Данила Прокопьевич    14.04.1973   \n",
       "\n",
       "       Номер телефона     Электронная почта  \\\n",
       "0  +7 (951) 885-25-41  danila79@hotmail.com   \n",
       "\n",
       "                                Адрес прописки  \\\n",
       "0  Россия, г. Иркутск, Кирова ул., д. 1 кв.212   \n",
       "\n",
       "                                  Фактический адрес Серия и номер паспорта  \\\n",
       "0  Россия, г. Екатеринбург, Кирова ул., д. 1 кв.107            4844 295530   \n",
       "\n",
       "  Серия паспорта Номер паспорта Код подразделения  \\\n",
       "0           4844         295530           330-554   \n",
       "\n",
       "                         Кем выдан Дата выдачи паспорта     ИНН ФЗ/ИП  \\\n",
       "0  ОУФМС России по г. Екатеринбург           08.08.2020  158493217864   \n",
       "\n",
       "            СНИЛС               ОМС  \\\n",
       "0  707-920-812 02  5950614844448865   \n",
       "\n",
       "                                         Направление  \n",
       "0  02.03.03 Математическое обеспечение и админист...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "efe0273d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ФИО</th>\n",
       "      <th>Номер телефона</th>\n",
       "      <th>Фактический адрес</th>\n",
       "      <th>Серия паспорта</th>\n",
       "      <th>Номер паспорта</th>\n",
       "      <th>СНИЛС</th>\n",
       "      <th>Статус</th>\n",
       "      <th>Подтверждающий документ</th>\n",
       "      <th>Серия документа</th>\n",
       "      <th>Номер документа</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Байдавлетова Виктория Юрьевна</td>\n",
       "      <td>+7 (940) 710-41-74</td>\n",
       "      <td>Россия, г. Дербент, Красноармейская ул., д. 12...</td>\n",
       "      <td>4317</td>\n",
       "      <td>888888</td>\n",
       "      <td>409-535-029 76</td>\n",
       "      <td>ОВЗ</td>\n",
       "      <td>Справка</td>\n",
       "      <td>АЭС730</td>\n",
       "      <td>70172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ФИО      Номер телефона  \\\n",
       "0  Байдавлетова Виктория Юрьевна  +7 (940) 710-41-74   \n",
       "\n",
       "                                   Фактический адрес Серия паспорта  \\\n",
       "0  Россия, г. Дербент, Красноармейская ул., д. 12...           4317   \n",
       "\n",
       "  Номер паспорта           СНИЛС Статус Подтверждающий документ  \\\n",
       "0         888888  409-535-029 76    ОВЗ                 Справка   \n",
       "\n",
       "  Серия документа Номер документа  \n",
       "0          АЭС730           70172  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89c88ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Создаем в каждом датафрейме колонку с айди путем склеивания всех нужных колонок в одну строку\n",
    "first_df['ID_объединения'] = first_df.iloc[:, int_params_first_columns].sum(axis=1)\n",
    "second_df['ID_объединения'] = second_df.iloc[:, int_params_second_columns].sum(axis=1)\n",
    "# Удаляем все пробелы чтобы они не повлияли на слияние\n",
    "first_df['ID_объединения'] = first_df['ID_объединения'].apply(lambda x: x.replace(' ', ''))\n",
    "second_df['ID_объединения'] = second_df['ID_объединения'].apply(lambda x: x.replace(' ', ''))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80c56d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Обрабатываем дубликаты\n",
    "\n",
    "duplicates_first_df = first_df[first_df.duplicated(subset=['ID_объединения'],\n",
    "                                                   keep=False)]  # Сохраняем все значения у которых есть дубликаты в отдельный датафрейм\n",
    "\n",
    "first_df.drop_duplicates(subset=['ID_объединения'], keep=False, inplace=True)  # Удаляем дубликаты из датафрейма\n",
    "\n",
    "duplicates_second_df = second_df[second_df.duplicated(subset=['ID_объединения'],\n",
    "                                                      keep=False)]  # Сохраняем все значения у которых есть дубликаты в отдельный датафрейм\n",
    "second_df.drop_duplicates(subset=['ID_объединения'], keep=False, inplace=True)  # Удаляем дубликаты из датафрейма\n",
    "\n",
    "# # Проверяем размер датафрейма с дубликатами, если он больше 0 то выдаем сообшение пользователю\n",
    "if duplicates_first_df.shape[0] > 0:\n",
    "    messagebox.showwarning('Веста Обработка таблиц и создание документов ver 1.21',\n",
    "                           f'В первой таблице обнаружены дубликаты!!!\\nДля корректного объединения таблиц ,дубликаты перенесены в отдельный лист итоговой таблицы')\n",
    "if duplicates_second_df.shape[0] > 0:\n",
    "    messagebox.showwarning('Веста Обработка таблиц и создание документов ver 1.21',\n",
    "                           f'Во второй таблице обнаружены дубликаты!!!\\nДля корректного объединения таблиц ,дубликаты перенесены в отдельный лист итоговой таблицы')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd4f2863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Worksheet \"Дубликаты вторая таблица\">"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В результат объединения попадают совпадающие по ключу записи обеих таблиц и все строки из этих двух таблиц, для которых пар не нашлось. Порядок таблиц в запросе не\n",
    "\n",
    "# Создаем документ\n",
    "wb = openpyxl.Workbook()\n",
    "# создаем листы\n",
    "ren_sheet = wb['Sheet']\n",
    "ren_sheet.title = 'Таблица 1'\n",
    "wb.create_sheet(title='Таблица 2', index=1)\n",
    "wb.create_sheet(title='Совпадающие данные', index=2)\n",
    "wb.create_sheet(title='Обновленная таблица', index=3)\n",
    "wb.create_sheet(title='Объединённая таблица', index=4)\n",
    "# Создаем листы для дубликатов\n",
    "wb.create_sheet(title='Дубликаты первая таблица', index=5)\n",
    "wb.create_sheet(title='Дубликаты вторая таблица', index=6)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73258152",
   "metadata": {},
   "source": [
    "first_df.to_excel('new_first.xlsx',index=False)\n",
    "second_df.to_excel('new_second.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0f13634",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Проводим слияние\n",
    "itog_df = pd.merge(first_df, second_df, how='outer', left_on=['ID_объединения'], right_on=['ID_объединения'],\n",
    "                   indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f6969d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# копируем в отдельный датафрейм чтобы \n",
    "update_df = itog_df.copy()\n",
    "\n",
    "# получаем список с совпадающими колонками первой таблицы\n",
    "first_df_columns = [column for column in list(update_df.columns) if str(column).endswith('_x')]\n",
    "# получаем список с совпадающими колонками второй таблицы\n",
    "second_df_columns = [column for column in list(update_df.columns) if str(column).endswith('_y')]\n",
    "# Создаем из списка совпадающих колонок второй таблицы словарь, чтобы было легче обрабатывать\n",
    "# да конечно можно было сделать в одном выражении но как я буду читать это через 2 недели?\n",
    "dct_second_columns = {column.split('_y')[0]:column for column in second_df_columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b43e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b4695f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ФИО': 'ФИО_y',\n",
       " 'Номер телефона': 'Номер телефона_y',\n",
       " 'Фактический адрес': 'Фактический адрес_y',\n",
       " 'Серия паспорта': 'Серия паспорта_y',\n",
       " 'Номер паспорта': 'Номер паспорта_y',\n",
       " 'СНИЛС': 'СНИЛС_y'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_second_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "426c387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in first_df_columns:\n",
    "    # очищаем от _x\n",
    "    name_column = column.split('_x')[0]\n",
    "    update_df[column] = np.where(update_df['_merge']=='both',update_df[dct_second_columns[name_column]],update_df[column]) \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d989d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     update_df[column] = update_df.apply(lambda x:update_value(update_df[column],update_df[dct_second_columns[name_column]],\n",
    "#                                                              update_df['_merge']),axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d8fbe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_df.to_excel('update.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33550dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbd6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1255e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d148fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d78e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f75a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f695f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e850103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Создаем переменные содержащие в себе количество колонок в базовых датареймах\n",
    "first_df_quantity_cols = len(first_df.columns)  # не забываем что там добавилась колонка ID\n",
    "\n",
    "# Записываем каждый датафрейм в соответсвующий лист\n",
    "# Левая таблица\n",
    "left_df = itog_df[itog_df['_merge'] == 'left_only']\n",
    "left_df.drop(['_merge'], axis=1, inplace=True)\n",
    "\n",
    "# Удаляем колонки второй таблицы чтобы не мешались\n",
    "left_df.drop(left_df.iloc[:, first_df_quantity_cols:], axis=1, inplace=True)\n",
    "\n",
    "# Переименовываем колонки у которых были совпадение во второй таблице, в таких колонках есть добавление _x\n",
    "clean_left_columns = list(map(lambda x: x[:-2] if '_x' in x else x, list(left_df.columns)))\n",
    "left_df.columns = clean_left_columns\n",
    "for r in dataframe_to_rows(left_df, index=False, header=True):\n",
    "    wb['Таблица 1'].append(r)\n",
    "\n",
    "right_df = itog_df[itog_df['_merge'] == 'right_only']\n",
    "right_df.drop(['_merge'], axis=1, inplace=True)\n",
    "\n",
    "# Удаляем колонки первой таблицы таблицы чтобы не мешались\n",
    "right_df.drop(right_df.iloc[:, :first_df_quantity_cols - 1], axis=1, inplace=True)\n",
    "\n",
    "# Переименовываем колонки у которых были совпадение во второй таблице, в таких колонках есть добавление _x\n",
    "clean_right_columns = list(map(lambda x: x[:-2] if '_y' in x else x, list(right_df.columns)))\n",
    "right_df.columns = clean_right_columns\n",
    "\n",
    "for r in dataframe_to_rows(right_df, index=False, header=True):\n",
    "    wb['Таблица 2'].append(r)\n",
    "\n",
    "both_df = itog_df[itog_df['_merge'] == 'both']\n",
    "both_df.drop(['_merge'], axis=1, inplace=True)\n",
    "# Очищаем от _x  и _y\n",
    "clean_both_columns = clean_ending_columns(list(both_df.columns), name_first_df, name_second_df)\n",
    "both_df.columns = clean_both_columns\n",
    "\n",
    "for r in dataframe_to_rows(both_df, index=False, header=True):\n",
    "    wb['Совпадающие данные'].append(r)\n",
    "\n",
    "# Сохраняем общую таблицу\n",
    "# Заменяем названия индикаторов на более понятные\n",
    "itog_df['_merge'] = itog_df['_merge'].apply(lambda x: 'Данные из первой таблицы' if x == 'left_only' else\n",
    "('Данные из второй таблицы' if x == 'right_only' else 'Совпадающие данные'))\n",
    "itog_df['_merge'] = itog_df['_merge'].astype(str)\n",
    "\n",
    "clean_itog_df = clean_ending_columns(list(itog_df.columns), name_first_df, name_second_df)\n",
    "itog_df.columns = clean_itog_df\n",
    "for r in dataframe_to_rows(itog_df, index=False, header=True):\n",
    "    wb['Объединённая таблица'].append(r)\n",
    "\n",
    "# Записываем дубликаты в соответствующие листы\n",
    "for r in dataframe_to_rows(duplicates_first_df, index=False, header=True):\n",
    "    wb['Дубликаты первая таблица'].append(r)\n",
    "\n",
    "for r in dataframe_to_rows(duplicates_second_df, index=False, header=True):\n",
    "    wb['Дубликаты вторая таблица'].append(r)\n",
    "# генерируем текущее время\n",
    "t = time.localtime()\n",
    "current_time = time.strftime('%H_%M_%S', t)\n",
    "# Сохраняем итоговый файл\n",
    "wb.save(f'{path_to_end_folder_comparison}/Результат слияния 2 таблиц от {current_time}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81469cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e9077f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ea142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2604c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9b44a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c4e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3e7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b05fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449953ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c164ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb123b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
